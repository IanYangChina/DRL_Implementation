[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

# DRL_Implementation

- This repository will be filled with codes reproducing some DRL algos I'm interested in.
- Language: Python-3.6
- Main library: PyTorch-1.3.0, Mujoco-py-2.0.2.8, Gym-0.15.3  

### Algorithms to Implement
- [X] Hindsight DQN - Discrete
- [X] Hindsight DDPG - Continuous
- [ ] Hindsight TD3 - Discrete
- [ ] HIRO - Continuous
- [X] Option Hindsight DQN - Discrete
- [ ] Option Hindsight DDPG - Continuous

### Environments
- [X] GridWorld_MultiRoomKeyDoor (Discrete, Multi-goal, Customized)
- [X] OpenAI Gym Mujoco Robotic Goal Environment (Continuous, Official)
- [ ] OpenAI Gym Mujoco Robotic Multi-goal Environment (Continuous, Customized)

### Reference Papers
* [DQN](https://www.nature.com/articles/nature14236?wm=book_wap_0005)
* [DoubleDQN](https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/viewPaper/12389)
* [DDPG](https://arxiv.org/abs/1509.02971)
* [PER](https://arxiv.org/abs/1511.05952)
* [HER](http://papers.nips.cc/paper/7090-hindsight-experience-replay)
* [HIRO](http://papers.nips.cc/paper/7591-data-efficient-hierarchical-reinforcement-learning.pdf)
* [OptionFramework](https://www.sciencedirect.com/science/article/pii/S0004370299000521)
* [OptionCritic](https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/viewPaper/14858)

### Reference Repos
* [RL-Adventure-DDPG by higgsfield](https://github.com/higgsfield/RL-Adventure-2/blob/master/5.ddpg.ipynb)
* [OpenAI HER Baseline](https://github.com/openai/baselines/tree/master/baselines/her)
* [hindsight-experience-replay by TianhongDai](https://github.com/TianhongDai/hindsight-experience-replay)
